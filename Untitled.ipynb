{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057683a-b9aa-4337-b690-4d016bd37f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading url https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q2_K.gguf to path /tmp/llama_index/models/llama-2-7b-chat.Q2_K.gguf\n",
      "total size (MB): 2825.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2696it [15:09,  2.96it/s]                                                                                                                                      \n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /tmp/llama_index/models/llama-2-7b-chat.Q2_K.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 10\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q2_K:   65 tensors\n",
      "llama_model_loader: - type q3_K:  160 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q2_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 2.63 GiB (3.35 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.15 MiB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "from llama_index.llms.llama_cpp.llama_utils import (\n",
    "    messages_to_prompt,\n",
    "    completion_to_prompt,\n",
    ")\n",
    "import os\n",
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "\n",
    "llm = LlamaCPP(\n",
    "    model_url=\"https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q2_K.gguf\",\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=100,\n",
    "    # llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\n",
    "    context_window=4096,\n",
    "    # kwargs to pass to __call__()\n",
    "    generate_kwargs={},\n",
    "    # kwargs to pass to __init__()\n",
    "    # set to at least 1 to use GPU\n",
    "    model_kwargs={\"n_gpu_layers\": -1},\n",
    "    # transform inputs into Llama2 format\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    completion_to_prompt=completion_to_prompt,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f985f25d-0e5e-4ede-a00f-598b0c9d7bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I can provide you with detailed information about the Great Wall of China, including its historical significance, construction methods, and current state. The Great Wall was built over several dynasties and served as a defensive structure against invasions. It stretentreasures from 250e6 BC to 1644 AD.\n",
      "\n",
      "The wall is made up of various materials such as tamped earth, bricks, wood, and even reused building fragments. The Great Wall was built using three primary construction methods: through arches, battlements, and sectors. Through arches are the open sections between towers or fortresses along the wall. Battlements were used in areas where there were no gates or watchtowers, serving as a defensive barrier against invaders. Sectors were the individual parts of the wall that had their own unique features and purposes.\n",
      "\n",
      "Today, much of the Great Wall is well-preserved and can be visited by tourists in certain areas. However, some sections are less accessible or even lost to time. The most famous section is located near Beijing's Tian Quan Park, where you can see a well-preserved portion of the wall that"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   29370.69 ms\n",
      "llama_print_timings:      sample time =      90.95 ms /   256 runs   (    0.36 ms per token,  2814.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   29362.59 ms /    66 tokens (  444.89 ms per token,     2.25 tokens per second)\n",
      "llama_print_timings:        eval time =   56673.59 ms /   255 runs   (  222.25 ms per token,     4.50 tokens per second)\n",
      "llama_print_timings:       total time =   88232.08 ms /   321 tokens\n"
     ]
    }
   ],
   "source": [
    "response_iter = llm.stream_complete(\"Hello\")\n",
    "for response in response_iter:\n",
    "    print(response.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36294573-4468-439d-a32b-e8dfc944d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.json import JSONReader\n",
    "\n",
    "# Initialize JSONReader\n",
    "reader = JSONReader()\n",
    "\n",
    "# Load data from JSON file\n",
    "documents = reader.load_data(input_file=\"data.json\", extra_info={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc9fe142-7f25-4184-9d9e-829f93825434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama-index-readers-json\n",
      "  Using cached llama_index_readers_json-0.1.5-py3-none-any.whl (3.3 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-readers-json) (0.10.37.post1)\n",
      "Requirement already satisfied: wrapt in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.16.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2024.5.0)\n",
      "Requirement already satisfied: dataclasses-json in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (0.6.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (3.9.5)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (0.1.19)\n",
      "Requirement already satisfied: numpy in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2.31.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (3.8.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (8.3.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (3.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (6.0.1)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.2.14)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2.0.30)\n",
      "Requirement already satisfied: httpx in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (0.27.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (10.3.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (0.9.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.6.0)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.30.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (4.11.0)\n",
      "Requirement already satisfied: pandas in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2.2.2)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.7.1 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (3.7.4)\n",
      "Requirement already satisfied: jsonpath-ng<2.0.0,>=1.6.0 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.6.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (4.66.4)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/prash/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (0.7.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/prash/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/prash/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/prash/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/prash/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/prash/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/prash/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (6.0.5)\n",
      "Requirement already satisfied: ply in /home/prash/.local/lib/python3.10/site-packages (from jsonpath-ng<2.0.0,>=1.6.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (3.11)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/prash/.local/lib/python3.10/site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2.7.1)\n",
      "Requirement already satisfied: certifi in /home/prash/.local/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2024.2.2)\n",
      "Requirement already satisfied: anyio in /home/prash/.local/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (4.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/prash/.local/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/prash/.local/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (3.7)\n",
      "Requirement already satisfied: sniffio in /home/prash/.local/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/prash/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (0.14.0)\n",
      "Requirement already satisfied: joblib in /home/prash/.local/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.4.2)\n",
      "Requirement already satisfied: click in /home/prash/.local/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/prash/.local/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2024.5.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/prash/.local/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/prash/.local/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (3.3.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (6.4.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2.4.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (3.4.0)\n",
      "Requirement already satisfied: jinja2 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (3.1.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.0.5)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (8.2.3)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (0.3.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (59.6.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2.0.10)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.0.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/prash/.local/lib/python3.10/site-packages (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (24.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/prash/.local/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/prash/.local/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/prash/.local/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (3.21.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/prash/.local/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/prash/.local/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/prash/.local/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/prash/.local/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.2.1)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/prash/.local/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/prash/.local/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/prash/.local/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2.18.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.16.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/prash/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/prash/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (0.1.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/prash/.local/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/prash/.local/lib/python3.10/site-packages (from jinja2->spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /home/prash/.local/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-json) (1.1.1)\n",
      "Installing collected packages: llama-index-readers-json\n",
      "Successfully installed llama-index-readers-json-0.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip3 install llama-index-readers-json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38788cb3-d50e-49c0-bef6-b0f2b9103c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings, SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cba7109-9ef7-4df3-ae01-0a36a3bebb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prash/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "328fb1bb-7cc2-43bd-acc8-7f05a54a9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cae4aa2-6a7c-4c15-873f-a008aebffbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 3\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73d70d85-b74c-44fa-9726-ee4c247029cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import get_response_synthesizer\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.5)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d4c3a6c-6cb8-40f1-8675-72ae8f6e3f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3835.20 ms\n",
      "llama_print_timings:      sample time =      64.11 ms /   256 runs   (    0.25 ms per token,  3992.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   23074.40 ms /   256 runs   (   90.13 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =   23884.91 ms /   256 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** ttitedtthe ttinst,m\n",
       "\"\n",
       "t\n",
       "t\n",
       "tmin,\n",
       "tment,\n",
       "tformered\n",
       "tinstedin,mind as as as thema,mand as as the the them,minstsminst (tinstsinst,sent,the\n",
       "tiinst,inst,the,the:M:M,msh for,forment,instmminminst.instmingmentminst,inst,minst,mind,minstedinst,inst,inst,inst,they,inst,inst,inst,inst,inst, and as,inst,all,inst,as as,the,inst,inst as theinst,instinstinstinstinstinst,inst,inst,inst,Minstinstinst\n",
       "inst,inst,m,inst,inst,inst,inst,min,inst,instmentm.instmind,inst,inst.inst,inst,inst,inst,inst,inst as as,inst as as as as the,the as as as as,inst, as as as the insts and the theinst,inst,inst,inst,instinstinstinstininstinstinstinstinstinstinstinstinst"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"Hello\")\n",
    "display_response(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
